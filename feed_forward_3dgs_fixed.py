#!/usr/bin/env python3
"""
[ä¿®å¤ç‰ˆ] åŸºäºŽ DA3stream çš„å‰é¦ˆ 3DGS ç”Ÿæˆè„šæœ¬

å…³é”®ä¿®å¤ï¼š
1. æ­£ç¡®çš„åæ ‡ç³»è½¬æ¢ï¼šc2w â†’ w2c
2. ç§»é™¤è¿‡åº¦çš„é¢œè‰²å¢žå¼º
3. ä½¿ç”¨å®˜æ–¹ Monkey Patch æŠ€æœ¯æ³¨å…¥ Streaming æ•°æ®
"""

import os
import sys
import argparse
from pathlib import Path
from typing import Tuple

import numpy as np
import torch
import torchvision.transforms as T
from PIL import Image
from tqdm import tqdm

sys.path.insert(0, '/home/ltx/projects/Depth-Anything-3/src')

from depth_anything_3.api import DepthAnything3
from depth_anything_3.specs import Gaussians
from depth_anything_3.utils.gsply_helpers import export_ply, inverse_sigmoid

def load_streaming_results(streaming_dir: Path) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """åŠ è½½ DA3stream è¾“å‡ºæ•°æ®"""
    results_dir = streaming_dir / "results_output"
    npz_files = sorted(results_dir.glob("frame_*.npz"))
    if not npz_files: raise ValueError("æ²¡æ‰¾åˆ° npz æ–‡ä»¶")

    first_data = np.load(npz_files[0])
    H, W = first_data['image'].shape[:2]
    N = len(npz_files)

    images = np.zeros((N, H, W, 3), dtype=np.uint8)
    depths = np.zeros((N, H, W), dtype=np.float32)
    confs = np.zeros((N, H, W), dtype=np.float32)
    intrinsics = np.zeros((N, 3, 3), dtype=np.float32)

    print("åŠ è½½ DA3stream è¾“å‡ºæ•°æ®...")
    for i, npz_file in enumerate(tqdm(npz_files, desc="åŠ è½½æ•°æ®")):
        data = np.load(npz_file)
        images[i] = data['image']
        depths[i] = data['depth']
        confs[i] = data['conf']
        intrinsics[i] = data['intrinsics']

    poses_file = streaming_dir / "camera_poses.txt"
    # camera_poses.txt æ˜¯ c2w æ ¼å¼ (cam2world)
    c2w_poses = np.loadtxt(poses_file).reshape(-1, 4, 4)

    # ðŸ”‘ å…³é”®ä¿®å¤ï¼šè½¬æ¢ä¸º w2c (world2cam) æ ¼å¼
    # DA3 æ¨¡åž‹æœŸæœ›çš„æ˜¯ w2cï¼Œä¸æ˜¯ c2wï¼
    w2c_poses = np.linalg.inv(c2w_poses)

    min_n = min(N, w2c_poses.shape[0])
    return images[:min_n], depths[:min_n], confs[:min_n], w2c_poses[:min_n], intrinsics[:min_n]

def concatenate_gaussians(gaussians_list: list) -> Gaussians:
    return Gaussians(
        means=torch.cat([g.means for g in gaussians_list], dim=1),
        harmonics=torch.cat([g.harmonics for g in gaussians_list], dim=1),
        opacities=torch.cat([g.opacities for g in gaussians_list], dim=1),
        scales=torch.cat([g.scales for g in gaussians_list], dim=1),
        rotations=torch.cat([g.rotations for g in gaussians_list], dim=1),
    )

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--streaming-dir', type=str, required=True)
    parser.add_argument('--output-dir', type=str, default='./output/feed_forward_3dgs_fixed')
    parser.add_argument('--model-name', type=str, default='da3-giant')
    parser.add_argument('--frame-interval', type=int, default=10)
    parser.add_argument('--conf-threshold', type=float, default=0.85)
    parser.add_argument('--sample-ratio', type=float, default=1.0)
    args = parser.parse_args()

    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # åŠ è½½æ•°æ®ï¼ˆå·²ç»æ˜¯ w2c æ ¼å¼ï¼‰
    images, depths, confs, w2c_extrinsics, intrinsics = load_streaming_results(Path(args.streaming_dir))

    # æŠ½å¸§
    frame_indices = list(range(0, len(images), args.frame_interval))
    print(f"\né€‰æ‹© {len(frame_indices)} å¸§è¿›è¡Œåº•å±‚ GS èžåˆ...")

    # ========================================================
    # ðŸ”‘ æ ¸å¿ƒä¿®å¤ï¼šåæ ‡ç³»å½’ä¸€åŒ–
    # å°†ç¬¬ä¸€å¸§çš„ç›¸æœºä½å§¿ä½œä¸ºä¸–ç•Œåæ ‡ç³»çš„åŽŸç‚¹
    # ========================================================
    print("ðŸ”§ æ‰§è¡Œåæ ‡ç³»å½’ä¸€åŒ–ï¼ˆç¬¬ä¸€å¸§ä½œä¸ºä¸–ç•ŒåŽŸç‚¹ï¼‰...")
    first_w2c_inv = np.linalg.inv(w2c_extrinsics[frame_indices[0]])
    # åº”ç”¨å˜æ¢ï¼šT_new = T_first_inv * T_old
    # è¿™æ ·ç¬¬ä¸€å¸§å°±å˜æˆäº† Identity
    for i in range(len(w2c_extrinsics)):
        w2c_extrinsics[i] = first_w2c_inv @ w2c_extrinsics[i]
    print(f"  âœ“ ç¬¬ä¸€å¸§ç›¸æœºä½ç½®å·²è®¾ä¸ºä¸–ç•Œåæ ‡åŽŸç‚¹")

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    da3 = DepthAnything3(model_name=args.model_name).to(device)
    da3.eval()

    transform = T.Compose([
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    all_gaussians = []
    print("\nðŸš€ å¼€å§‹åº•å±‚å‰å‘æ¸²æŸ“èžåˆ...")

    # Monkey Patchï¼šæ³¨å…¥ Streaming æ•°æ®
    original_depth_head = da3.model._process_depth_head

    for idx in tqdm(frame_indices, desc="æ˜ å°„ 3DGS"):
        H, W = images[idx].shape[:2]

        img_tensor = transform(Image.fromarray(images[idx])).unsqueeze(0).unsqueeze(0).to(device)
        depth_tensor = torch.from_numpy(depths[idx]).unsqueeze(0).to(device) # (1, H, W)

        # ðŸ”‘ é‡è¦ï¼šä½¿ç”¨ w2c æ ¼å¼çš„ extrinsics
        ext_tensor = torch.from_numpy(w2c_extrinsics[idx]).unsqueeze(0).unsqueeze(0).float().to(device) # (1, 1, 4, 4)
        intrin_tensor = torch.from_numpy(intrinsics[idx]).unsqueeze(0).unsqueeze(0).float().to(device)

        # Monkey Patchï¼šæ³¨å…¥ Streaming æ·±åº¦å’Œä½å§¿
        def my_depth_head(feats, h, w):
            out = original_depth_head(feats, h, w)
            out.depth = depth_tensor
            return out

        def my_cam_est(feats, h, w, out):
            out.extrinsics = ext_tensor  # w2c æ ¼å¼
            out.intrinsics = intrin_tensor
            return out

        da3.model._process_depth_head = my_depth_head
        da3.model._process_camera_estimation = my_cam_est

        with torch.no_grad():
            outputs = da3.model(
                img_tensor,
                extrinsics=ext_tensor,  # w2c æ ¼å¼
                intrinsics=intrin_tensor,
                infer_gs=True
            )
            frame_gs = outputs.gaussians

        da3.model._process_depth_head = original_depth_head

        # ç½®ä¿¡åº¦å‰ªæžä¸Žé™é‡‡æ ·
        conf_flat = torch.from_numpy(confs[idx]).view(-1).to(device)
        valid_mask = conf_flat > args.conf_threshold

        if args.sample_ratio < 1.0:
            valid_idx = torch.where(valid_mask)[0]
            num_keep = int(len(valid_idx) * args.sample_ratio)
            keep_idx = valid_idx[torch.randperm(len(valid_idx))[:num_keep]]
            new_mask = torch.zeros_like(valid_mask)
            new_mask[keep_idx] = True
            valid_mask = new_mask

        filtered_gs = Gaussians(
            means=frame_gs.means[:, valid_mask],
            harmonics=frame_gs.harmonics[:, valid_mask],
            opacities=frame_gs.opacities[:, valid_mask],
            scales=frame_gs.scales[:, valid_mask],
            rotations=frame_gs.rotations[:, valid_mask]
        )
        all_gaussians.append(filtered_gs)

    final_gaussians = concatenate_gaussians(all_gaussians)
    num_gaussians = final_gaussians.means.shape[1]
    print(f"\næ€»è®¡ä¿ç•™é«˜æ–¯çƒæ•°é‡: {num_gaussians:,}")

    # ========================================================
    # ðŸ”‘ é¢œè‰²å¤„ç†ï¼šç§»é™¤è¿‡åº¦çš„å¢žå¼ºï¼Œä½¿ç”¨ä¿å®ˆç­–ç•¥
    # ========================================================
    print("ðŸŽ¨ åº”ç”¨ä¿å®ˆçš„é¢œè‰²å¢žå¼º...")

    harmonics_dc = final_gaussians.harmonics[..., 0:1]  # (1, N, 3, 1)
    print(f"  DC åˆ†é‡åŽŸå§‹èŒƒå›´: [{harmonics_dc.min():.4f}, {harmonics_dc.max():.4f}]")

    # ä¿å®ˆç­–ç•¥ï¼šä»…è½»å¾®å¢žå¼ºï¼Œé¿å…é¢œè‰²å¤±çœŸ
    # ç›®æ ‡ï¼šå°†åŠ¨æ€èŒƒå›´ä»Ž ~0.1 æ‰©å±•åˆ° ~0.3
    enhancement_factor = 2.0
    harmonics_dc_enhanced = harmonics_dc * enhancement_factor

    print(f"  DC åˆ†é‡å¢žå¼ºåŽèŒƒå›´: [{harmonics_dc_enhanced.min():.4f}, {harmonics_dc_enhanced.max():.4f}]")

    final_gaussians.harmonics[..., 0:1] = harmonics_dc_enhanced
    print(f"  âœ“ é¢œè‰²å·²å¢žå¼º {enhancement_factor}x")

    # å¯¼å‡º PLY
    ply_dir = output_dir / "gs_ply"
    ply_dir.mkdir(parents=True, exist_ok=True)
    ply_path = ply_dir / "0000_fixed.ply"

    print("ðŸ’¾ æ­£åœ¨å¯¼å‡º PLY æ–‡ä»¶...")

    gs_means = final_gaussians.means[0]
    gs_scales = final_gaussians.scales[0]
    gs_rotations = final_gaussians.rotations[0]
    gs_harmonics = final_gaussians.harmonics[0]
    gs_opacities_inv = inverse_sigmoid(final_gaussians.opacities[0])

    export_ply(
        means=gs_means,
        scales=gs_scales,
        rotations=gs_rotations,
        harmonics=gs_harmonics,
        opacities=gs_opacities_inv,
        path=ply_path,
        shift_and_scale=False,
        save_sh_dc_only=True,
        match_3dgs_mcmc_dev=False
    )

    file_size_mb = Path(ply_path).stat().st_size / (1024 * 1024)
    print(f"âœ“ å®Œæˆï¼PLY æ–‡ä»¶å·²ä¿å­˜è‡³: {ply_path} ({file_size_mb:.1f} MB)")
    print()
    print("å…³é”®ä¿®å¤:")
    print("  1. âœ… c2w â†’ w2c åæ ‡ç³»è½¬æ¢")
    print("  2. âœ… ç¬¬ä¸€å¸§åæ ‡ç³»å½’ä¸€åŒ–")
    print("  3. âœ… ä¿å®ˆçš„é¢œè‰²å¢žå¼ºç­–ç•¥")

if __name__ == '__main__':
    main()
