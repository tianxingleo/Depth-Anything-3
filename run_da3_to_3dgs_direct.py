import subprocess
import os
import shutil
import sys
from pathlib import Path
import numpy as np
from PIL import Image
import struct

# ================= ğŸ”§ è·¯å¾„é…ç½® =================
DA3_OUTPUT = Path("/home/ltx/projects/Depth-Anything-3/output/sugar_streaming")
WS_ROOT = DA3_OUTPUT / "da3_3dgs_pipeline"
CONDA_PREFIX = "/home/ltx/my_envs/gs_linux_backup"
NS_ENV_BIN = f"{CONDA_PREFIX}/bin"

# ç›´æ¥ä½¿ç”¨ç¯å¢ƒä¸­çš„ python è§£é‡Šå™¨æ¥è¿è¡Œè„šæœ¬ï¼Œé¿å… shebang å¯¼è‡´çš„ python3.10 æ‰¾ä¸åˆ°é”™è¯¯
PYTHON_EXE = f"{NS_ENV_BIN}/python"
NS_TRAIN = f"{NS_ENV_BIN}/ns-train"
NS_EXPORT = f"{NS_ENV_BIN}/ns-export"

# ================= ğŸ› ï¸ æ ¼å¼è½¬æ¢é€»è¾‘ =================

def rotmat_to_quat(R):
    tr = np.trace(R)
    if tr > 0:
        S = np.sqrt(tr + 1.0) * 2
        qw, qx, qy, qz = 0.25 * S, (R[2, 1] - R[1, 2]) / S, (R[0, 2] - R[2, 0]) / S, (R[1, 0] - R[0, 1]) / S
    elif (R[0, 0] > R[1, 1]) and (R[0, 0] > R[2, 2]):
        S = np.sqrt(1.0 + R[0, 0] - R[1, 1] - R[2, 2]) * 2
        qw, qx, qy, qz = (R[2, 1] - R[1, 2]) / S, 0.25 * S, (R[0, 1] + R[1, 0]) / S, (R[0, 2] + R[2, 0]) / S
    elif R[1, 1] > R[2, 2]:
        S = np.sqrt(1.0 + R[1, 1] - R[0, 0] - R[2, 2]) * 2
        qw, qx, qy, qz = (R[0, 2] - R[2, 0]) / S, (R[0, 1] + R[1, 0]) / S, 0.25 * S, (R[1, 2] + R[2, 1]) / S
    else:
        S = np.sqrt(1.0 + R[2, 2] - R[0, 0] - R[1, 1]) * 2
        qw, qx, qy, qz = (R[1, 0] - R[0, 1]) / S, (R[0, 2] + R[2, 0]) / S, (R[1, 2] + R[2, 1]) / S, 0.25 * S
    return np.array([qw, qx, qy, qz])

def convert_da3_to_colmap(source_dir, target_sparse_dir):
    print("ğŸ“¦ [æ ¼å¼è½¬æ¢] æ­£åœ¨å°† DA3 Poses & PCD è½¬æ¢ä¸º COLMAP æ ¼å¼...")
    target_sparse_dir.mkdir(parents=True, exist_ok=True)
    
    intrinsics = np.loadtxt(source_dir / "intrinsic.txt")
    poses_c2w = np.loadtxt(source_dir / "camera_poses.txt").reshape(-1, 4, 4)
    img_names = sorted([f.name for f in (source_dir / "extracted").glob("*.png")])
    
    if not img_names:
        raise ValueError(f"åœ¨ {source_dir / 'extracted'} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡ã€‚")

    with Image.open(source_dir / "extracted" / img_names[0]) as img:
        orig_w, orig_h = img.size
    
    # 1. å†™å…¥ cameras.txt
    with open(target_sparse_dir / "cameras.txt", "w") as f:
        # åŸºäº 280x504 çš„ç¼©æ”¾é€»è¾‘ (æˆ–è€…æ ¹æ® intrinsic[0][2]*2 è‡ªåŠ¨æ¨æ–­)
        ref_w = intrinsics[0][2] * 2
        ref_h = intrinsics[0][3] * 2
        scale_x = orig_w / ref_w
        scale_y = orig_h / ref_h
        
        fx, fy, cx, cy = intrinsics[0][0]*scale_x, intrinsics[0][1]*scale_y, intrinsics[0][2]*scale_x, intrinsics[0][3]*scale_y
        f.write(f"1 PINHOLE {orig_w} {orig_h} {fx} {fy} {cx} {cy}\n")

    # 2. å†™å…¥ images.txt
    print("ğŸ“¸ [æ ¼å¼è½¬æ¢] ç”Ÿæˆ images.txt...")
    with open(target_sparse_dir / "images.txt", "w") as f:
        for i, (pose_c2w, name) in enumerate(zip(poses_c2w, img_names)):
            pose_w2c = np.linalg.inv(pose_c2w)
            R = pose_w2c[:3, :3]
            t = pose_w2c[:3, 3]
            q = rotmat_to_quat(R)
            f.write(f"{i+1} {q[0]} {q[1]} {q[2]} {q[3]} {t[0]} {t[1]} {t[2]} 1 {name}\n\n")

    # 3. å†™å…¥ points3D.txt
    print("ğŸ’ [æ ¼å¼è½¬æ¢] è§£æ PLY PCD...")
    pcd_path = source_dir / "pcd" / "combined_pcd.ply"
    
    with open(pcd_path, 'rb') as f:
        header = ""
        while True:
            line = f.readline().decode('ascii')
            header += line
            if line.startswith("end_header"): break
        num_vertices = 0
        for line in header.split('\n'):
            if line.startswith("element vertex"):
                num_vertices = int(line.split()[-1])
        data = f.read()
    
    # è§£æäºŒè¿›åˆ¶ PLY (x,y,z ä¸º float, r,g,b ä¸º uchar)
    struct_fmt = "fffBBB"
    row_size = len(data) // num_vertices
    
    with open(target_sparse_dir / "points3D.txt", "w") as f_out:
        for i in range(num_vertices):
            offset = i * row_size
            v = struct.unpack_from(struct_fmt, data, offset)
            # POINT3D_ID, X, Y, Z, R, G, B, ERROR, TRACK
            f_out.write(f"{i+1} {v[0]} {v[1]} {v[2]} {v[3]} {v[4]} {v[5]} 0\n")
    
    print(f"âœ… è½¬æ¢å®Œæˆ: {len(img_names)} å¸§å’Œ {num_vertices} ä¸ªç‚¹å·²æ³¨å†Œã€‚")

# ================= ğŸš€ ä¸»æµç¨‹ =================

def run_pipeline():
    # é‡æ–°åˆå§‹åŒ–å·¥ä½œç›®å½•
    if WS_ROOT.exists(): shutil.rmtree(WS_ROOT)
    WS_ROOT.mkdir(parents=True)
    
    data_dir = WS_ROOT / "data"
    sparse_0 = data_dir / "colmap" / "sparse" / "0"
    dest_imgs = data_dir / "images"
    dest_imgs.mkdir(parents=True)

    print("ğŸ–¼ï¸ åŒæ­¥å›¾ç‰‡ä¸­...")
    for img in (DA3_OUTPUT / "extracted").glob("*.png"):
        shutil.copy2(img, dest_imgs)
    
    convert_da3_to_colmap(DA3_OUTPUT, sparse_0)

    print("ğŸ”¥ [Direct Pipeline] å¼€å§‹ 3DGS è®­ç»ƒ...")
    
    # å¢åŠ ç¯å¢ƒå˜é‡é…ç½®ï¼Œè§£å†³ setuptools/_distutils_hack å¯¼è‡´çš„ AssertionError
    env = os.environ.copy()
    env["SETUPTOOLS_USE_DISTUTILS"] = "stdlib"

    # ä½¿ç”¨ PYTHON_EXE æ˜¾å¼è°ƒç”¨ ns-train ä»¥ç»•è¿‡ shebang æŠ¥é”™
    cmd = [
        PYTHON_EXE, NS_TRAIN, "splatfacto", 
        "--data", str(data_dir), 
        "--output-dir", str(WS_ROOT / "outputs"),
        "--experiment-name", "da3_direct",
        "--pipeline.model.random-init", "False",
        "--max-num-iterations", "15000",
        "colmap"
    ]
    
    print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    subprocess.run(cmd, check=True, env=env)

    # ================= ğŸ“¤ è‡ªåŠ¨å¯¼å‡º PLY =================
    print("ğŸ”¥ [Direct Pipeline] è®­ç»ƒå®Œæˆï¼Œæ­£åœ¨å¯¼å‡º Gaussian Splatting PLY...")
    
    # æŸ¥æ‰¾åˆšæ‰ç”Ÿæˆçš„ config.yml
    config_paths = list((WS_ROOT / "outputs/da3_direct").rglob("config.yml"))
    if config_paths:
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°ç”Ÿæˆçš„ä¸€ä¸ª
        latest_config = max(config_paths, key=lambda p: p.stat().st_mtime)
        export_dir = WS_ROOT / "export"
        
        export_cmd = [
            PYTHON_EXE, NS_EXPORT, "gaussian-splat",
            "--load-config", str(latest_config),
            "--output-dir", str(export_dir)
        ]
        
        print(f"æ‰§è¡Œå¯¼å‡ºå‘½ä»¤: {' '.join(export_cmd)}")
        subprocess.run(export_cmd, check=True, env=env)
        print(f"âœ… å¯¼å‡ºæˆåŠŸï¼PLY æ–‡ä»¶å·²ä¿å­˜åœ¨: {export_dir}")
    else:
        print("âš ï¸ æœªå‘ç°è®­ç»ƒç”Ÿæˆçš„ config.ymlï¼Œæ— æ³•å¯¼å‡º PLYã€‚")

if __name__ == "__main__":
    run_pipeline()
